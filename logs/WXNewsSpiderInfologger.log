2017-04-22 11:03:57 [scrapy.utils.log] INFO: Scrapy 1.3.2 started (bot: weixin)
2017-04-22 11:03:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'weixin', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_DOMAIN': 4, 'COOKIES_ENABLED': False, 'DEPTH_LIMIT': 2, 'DOWNLOAD_DELAY': 5, 'DOWNLOAD_TIMEOUT': 10, 'LOG_FILE': './logs/WXNewsSpiderInfologger.log', 'NEWSPIDER_MODULE': 'weixin.spiders', 'SPIDER_MODULES': ['weixin.spiders']}
2017-04-22 11:03:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-22 11:03:57 [wxNewsSpider] INFO: Reading start URLs from redis key 'WXNews:urls' (batch size: 4, encoding: utf-8
2017-04-22 11:03:57 [py.warnings] WARNING: D:\Anaconda3\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-22 11:03:57 [py.warnings] WARNING: D:\PyCharm\scrapyworm\weixin\weixin\middlewares.py:17: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-22 11:03:57 [py.warnings] WARNING: D:\PyCharm\scrapyworm\weixin\weixin\middlewares.py:19: ScrapyDeprecationWarning: Module `scrapy.contrib.downloadermiddleware.httpproxy` is deprecated, use `scrapy.downloadermiddlewares.httpproxy` instead
  from scrapy.contrib.downloadermiddleware.httpproxy import HttpProxyMiddleware

2017-04-22 11:03:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weixin.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-22 11:03:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-22 11:03:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-04-22 11:03:57 [scrapy.core.engine] INFO: Spider opened
2017-04-22 11:03:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-22 11:03:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2017-04-22 11:03:57 [py.warnings] WARNING: D:\PyCharm\scrapyworm\weixin\weixin\middlewares.py:93: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg('>>>> UA %s' % request.headers)

2017-04-22 11:03:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14']}
2017-04-22 11:03:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre']}
2017-04-22 11:03:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre']}
2017-04-22 11:03:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14']}
2017-04-22 11:03:58 [py.warnings] WARNING: D:\PyCharm\scrapyworm\weixin\weixin\middlewares.py:96: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg('>>>> response.status %s' % response.status)

2017-04-22 11:03:58 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:03:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:03:58 [wxNewsSpider] DEBUG: Read 4 requests from 'WXNews:urls'
2017-04-22 11:03:58 [root] INFO: we are coming
2017-04-22 11:03:59 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)']}
2017-04-22 11:03:59 [root] INFO: we are coming
2017-04-22 11:04:02 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:04:02 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5']}
2017-04-22 11:04:02 [root] INFO: we are coming
2017-04-22 11:04:03 [root] INFO: we are coming
2017-04-22 11:04:08 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:04:08 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7']}
2017-04-22 11:04:08 [root] INFO: we are coming
2017-04-22 11:04:09 [root] INFO: we are coming
2017-04-22 11:04:12 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:04:12 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)']}
2017-04-22 11:04:12 [root] INFO: we are coming
2017-04-22 11:04:13 [root] INFO: we are coming
2017-04-22 11:04:17 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:17 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1']}
2017-04-22 11:04:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:21 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:21 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1']}
2017-04-22 11:04:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E4%B8%89%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:26 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:26 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1']}
2017-04-22 11:04:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:33 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:33 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7']}
2017-04-22 11:04:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:40 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:45 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%A5%94%E8%B7%91%E5%90%A7%E5%85%84%E5%BC%9F%E7%AC%AC%E5%9B%9B%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:51 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E6%9A%B4%E8%B5%B0%E5%A4%A7%E4%BA%8B%E4%BB%B6%E7%AC%AC%E4%BA%94%E5%AD%A3&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:57 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:04:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:04:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%AF%BB%E6%83%85%E8%AE%B0&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%BA%A2-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:04:57 [wxNewsSpider] DEBUG: Read 4 requests from 'WXNews:urls'
2017-04-22 11:04:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)']}
2017-04-22 11:04:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5']}
2017-04-22 11:04:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1']}
2017-04-22 11:04:57 [scrapy.log] INFO: >>>> UA {b'User-Agent': [b'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1']}
2017-04-22 11:04:57 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2017-04-22 11:05:04 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:05:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:05:04 [root] INFO: we are coming
2017-04-22 11:05:05 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)']}
2017-04-22 11:05:05 [root] INFO: we are coming
2017-04-22 11:05:10 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:05:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E9%80%86%E6%88%98&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:05:10 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6']}
2017-04-22 11:05:10 [root] INFO: we are coming
2017-04-22 11:05:11 [root] INFO: we are coming
2017-04-22 11:05:17 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:05:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E7%A9%BF%E8%B6%8A%E7%81%AB%E7%BA%BF&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:05:17 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E9%80%86%E6%88%98&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)']}
2017-04-22 11:05:18 [root] INFO: we are coming
2017-04-22 11:05:19 [root] INFO: we are coming
2017-04-22 11:05:21 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:05:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E7%81%AB%E7%BA%BF%E7%B2%BE%E8%8B%B1&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C> (referer: http://weixin.sogou.com/)
2017-04-22 11:05:21 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E7%A9%BF%E8%B6%8A%E7%81%AB%E7%BA%BF&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20']}
2017-04-22 11:05:22 [root] INFO: we are coming
2017-04-22 11:05:23 [root] INFO: we are coming
2017-04-22 11:05:26 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:05:26 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E7%81%AB%E7%BA%BF%E7%B2%BE%E8%8B%B1&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)']}
2017-04-22 11:05:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=2> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
2017-04-22 11:05:32 [scrapy.log] INFO: >>>> response.status 200
2017-04-22 11:05:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
2017-04-22 11:05:32 [scrapy.log] INFO: >>>> UA {b'Referer': [b'http://weixin.sogou.com/weixin?type=2&query=%E7%81%AB%E7%BA%BF%E7%B2%BE%E8%8B%B1&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C'], b'User-Agent': [b'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2']}
2017-04-22 11:05:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C&page=3> (referer: http://weixin.sogou.com/weixin?type=2&query=%E5%89%91%E7%81%B5&ie=utf8&s_from=input&_sug_=n&_sug_type_=&tp=%E6%9C%80%E7%81%AB%E6%B8%B8%E6%88%8F-%E6%90%9C%E7%8B%97%E7%83%AD%E6%90%9C%E6%A6%9C)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\PyCharm\scrapyworm\weixin\weixin\spiders\wxNews.py", line 80, in parse_item
    word = unquote(words)
  File "D:\Anaconda3\lib\urllib\parse.py", line 601, in unquote
    string.split
AttributeError: 'list' object has no attribute 'split'
